% LaTeX source for ``การเรียนรู้ของเครื่องสำหรับเคมีควอนตัม (Machine Learning for Quantum Chemistry)''
% Copyright (c) 2022 รังสิมันต์ เกษแก้ว (Rangsiman Ketkaew).

% License: Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)
% https://creativecommons.org/licenses/by-nc-nd/4.0/

\chapter{โมเดล ML แบบพิเศษสำหรับเคมีควอนตัม}
\label{ch:chem_ml}

%--------------------------
\section{SchNet และ SchNetOrb}
%--------------------------

%--------------------------
\section{GDML และ sGDML}
%--------------------------

%--------------------------
\section{$\Delta$ML}
%--------------------------

Delta-ML ($\Delta$ML) ซึ่งเป็นเทคนิคนึงที่ใช้ค่าความแตกต่างระหว่างค่า reference จากวิธีการคำนวณที่มีความแม่นยำต่ำกับความแม่นยำสูงมาใช้ในการเทรนโมเดล 
ช่วยให้โมเดลสามารถเรียนรู้การเชื่อมโยงหรือ scale ไปยังค่า reference ที่มาจากวิธีที่มีความแม่นยำสูงได้ 
อย่างเช่นใช้ค่าความแตกต่างของพลังงานจากวิธี DFT และ CCSD(T) ($y_{DFT} - y_{CCSD(T)}$) มาเทรนโมเดล

$\Delta$ML นี้จริง ๆ ก็เป็นเทคนิคอันนึงที่มีแนวคิดมาจากความพยายามที่ต้องการจะทำให้โมเดลสามารถเรียนรู้ได้จากค่าความผิดพลาด (error) 
โดยเริ่มมีการเอามาใช้กันมากขึ้นในช่วงปีที่ผ่านมา (ในช่วงแรกถูกใช้เยอะแค่ในเฉพาะกลุ่มวิจัยในโซนยุโรป สำหรับการเอามาทำนาย energy 
แล้วก็ energy gradient (force) ของโมเลกุล) ซึ่ง concept ของ ∆ML จริง ๆ คือเป็นแค่การเรียนรู้ค่าความแตกต่างระหว่าง label 
ที่ได้มาจากสองวิธีที่แตกต่างกัน เช่น DFT กับ CCSD ($y^{DFT} - y^{CCSD}$) จึงเป็นที่มาว่าทำไมถึงเรียกว่า Detla ($\Delta$)

%--------------------------
\section{Graph Neural Network}
%--------------------------

Graph Neural Network หรือโครงข่ายประสาทแบบกราฟ เป็น NN รูปแบบหนึ่งซึ่งใช้การมองโครงสร้างข้อมูลให้อยู่ในรูปแบบของกราฟ
โดยไอเดียนี้ได้ถูกเสนอตั้งแต่ปี ค.ศ. 2008\cite{scarselli2009,zhou2020}

%--------------------------
\subsection{Message Passing Neural Network}
%--------------------------

Message Passing Neural Network หรือ MPNN ถูกนำเสนอครั้งแรกเมื่อปี ค.ศ. 2018\cite{gilmer2017}

%--------------------------
\section{Molecule Attention Transformer}
%--------------------------

% LaTeX source for ``การเรียนรู้ของเครื่องสำหรับเคมีควอนตัม (Machine Learning for Quantum Chemistry)''
% Copyright (c) 2022 รังสิมันต์ เกษแก้ว (Rangsiman Ketkaew).

% License: Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)
% https://creativecommons.org/licenses/by-nc-nd/4.0/

\chapter{การเรียนรู้ของเครื่อง}
\label{ch:ml}

\idxboth{การเรียนรู้ของเครื่อง}{Machine Learning}
\idxboth{การฝึกสอนโมเดล}{Model Training}

%--------------------------
\section{ความสำคัญของการเรียนรู้ของเครื่อง}
\label{sec:why_ml}
%--------------------------

การเรียนรู้ของเครื่อง (Machine Learning หรือ ML)\footnote{Arthur L. Samuel นักคอมพิวเตอร์ชาวอเมริกันและหนึ่งในผู้บุกเบิกสาขา%
ปัญญาประดิษฐ์ เป็นคนแรกที่เริ่มใช้คำว่า Machine Learning ตั้งแต่ปี ค.ศ. 1959 เป็นต้นมา\autocite{samuel1959}} เป็นศาสตร์ที่เชื่อม%
โยงวิชาสถิติ คณิตศาสตร์ และวิทยาการคอมพิวเตอร์เข้าด้วยกัน อธิบายง่าย ๆ คือมนุษย์พยายามทำให้เครื่องจักรนั้นมี \enquote{สติปัญญา} หรือ 
\enquote{ความฉลาด} และมีความสามารถในการเรียนรู้สิ่งต่าง ๆ ได้ด้วยตัวเอง โดยกระบวนการดังกล่าวนั้นจะเกี่ยวข้องกับการฝึกสอนเครื่องจักร%
จนกระทั่งเครื่องจักรสามารถเรียนรู้และค่อย ๆ พัฒนาการทำงานต่าง ๆ ได้โดยไม่ต้องพึ่งการตั้งโปรแกรม ซึ่งในบริบทนี้เครื่องจักรที่เรารู้จักกันดีก็คือ%
อุปกรณ์ที่มีหน่วยประมวลผล (Processing Unit) เช่น คอมพิวเตอร์ ที่ถูกสั่งงานหรือควบคุมผ่านซอฟต์แวร์ในรูปแบบของโปรแกรมนั่นเอง 
โดยวิธีการก็คือเราป้อนข้อมูลเข้าไปให้กับโปรแกรม โปรแกรมจะทำการสร้างโมเดล (Model) ที่สามารถอธิบายความสัมพันธ์ในข้อมูลที่เราป้อนเข้าไปได้ 
ซึ่งขั้นตอนที่เกิดขึ้นระหว่างการเรียนรู้ก็คือการฝึกสอนโมเดล (Model Training) ซึ่งโปรแกรมสามารถแปลงข้อมูลทั้งหมดเป็นโมเดลที่ปรับปรุงได้ 
นั่นหมายความว่าเทคโนโลยี ML สามารถทำให้คอมพิวเตอร์เรียนรู้วิธีทำงานของมนุษย์ได้ โดยเฉพาะการลอกเลียนแบบ (Imitation) กิจกรรมที่%
ทำซ้ำหรือเกิดขึ้นแบบเดิมจนมีแบบแผน (Pattern) ยกตัวอย่างเช่น ถ้าเรามีข้อมูล 2 ตัวแปร $(x,y)$ เราใช้ ML เพื่อหาฟังก์ชันที่สามารถเชื่อมโยง 
(Correlate) ความสัมพันธ์ระหว่างสองตัวแปรนี้ได้ $f: x\rightarrow y$

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{fig/cyborg.png}
    \caption{หุ่นยนต์ที่มีสมองเหมือนกับมนุษย์ที่มีความนึกคิดและสติปัญญา (เครดิตภาพ: https://pixabay.com)}
    \label{fig:cyborg}
\end{figure}

ML ได้ถูกพัฒนาเรื่อยมาเป็นระยะเวลาหลายทศวรรษ จุดเริ่มต้นที่นับได้ว่าสำคัญที่สุดของปัญญาประดิษฐ์เกิดขึ้นในปี ค.ศ. 1943 โดยนักตรรกศาสตร์
Walter Pitts และนักประสาทวิทยา Warren McCulloch ได้ตีพิมพ์ผลงานวิจัยที่เสนออัลกอริทึมคณิตศาสตร์ของโครงข่ายประสาท (Neural 
Network) และในปี ค.ศ. 1950 นักคณิตศาสตร์และนักถอดรหัสชื่อดัง Alan M. Turing\footnote{Alan M. Turing เป็นอัจฉริยะด้าน%
คณิตศาสตร์และการคำนวณ จบการศึกษาปริญญาตรีจาก University of Cambridge และปริญญาเอกจาก Princeton University 
โดยในช่วงสงครามโลก Alan ได้สร้างเครื่องถอดรหัสที่ชื่อว่า Bombe เพื่อมาต่อสู้กับเครื่องเข้ารหัส Enigma ซึ่งได้มีการประเมินไว้ว่าผลงานของ Alan 
ได้ช่วยชีวิตไว้ได้หลายล้านคน} ได้เสนอการทดสอบของทัวริง (The Turing Test)\autocite{turing1950} ซึ่งเป็นแนวคิดในการทดสอบ%
ความมีสติปัญญาของเครื่องจักร โดยหนึ่งในการทดสอบอันโด่งดังก็คือเกมเลียนแบบ (Imitation Game)\footnote{ผู้อ่านสามารถอ่านบทความ%
งานวิจัยต้นฉบับของ Alan Turing ได้ที่ \url{https://academic.oup.com/mind/article/LIX/236/433/986238} หรือดูภาพยนต์เรื่อง 
The Imitation Game \url{https://www.imdb.com/title/tt2084970}} หลังจากนั้นได้มีเหตุการณ์สำคัญเกิดขึ้นอีกมากมาย เช่น 
Arthur L. Samuel ได้เขียนโปรแกรมเล่นหมากฮอสโปรแกรมแรกของโลกให้กับ IBM ในปี ค.ศ. 1952 และอัลกอริทึม Nearest Neighbor 
ถูกคิดค้นขึ้นในช่วงปี ค.ศ. 1967 และในปี ค.ศ. 1996 IBM ได้พัฒนาโปรแกรมที่ชื่อว่า Deep Blue ที่สามารถเอาชนะนักหมากรุกมือวางอันดับ%
หนึ่งของโลกได้สำเร็จ

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{fig/malaria-parasite-protein-deepmind.jpeg}
    \caption{แบบจำลองโครงสร้างสามมิติการพับของโปรตีน Pfs48/45 ซึ่งเป็นองค์ประกอบสำคัญของปรสิตมาลาเรีย โครงสร้างนี้ทำนายด้วยโมเดล 
    ปัญญาประดิษฐ์ AlphaFold ซึ่งถูกพัฒนาโดย DeepMind (เครดิตภาพ: DeepMind)}
    \label{fig:malaria_parasite}
\end{figure}

นับตั้งแต่ปี ค.ศ. 2000 เป็นต้นมานั้นเรียกได้ว่าเป็นช่วงของการพัฒนาปัญญาประดิษฐ์แบบสมัยใหม่ก็ว่าได้ จุดเปลี่ยนที่น่าสนใจที่ทำให้คนหันมาสนใจ%
และให้ความสำคัญกับ ML ก็คือในช่วงระยะเวลา 10 ปีที่ผ่านมาได้มีเหตุการณ์สำคัญที่สร้างแรงกระเพื่อมแก่มวลมนุษยชาติ เช่น ในปี ค.ศ. 2011 
Apple ได้ปล่อยผลิตภัณฑ์ที่ชื่อ Siri ซึ่งเป็นผู้ช่วยเสมือน (Intelligent Virtual Assistant) อันแสนฉลาดออกมา และในปี ค.ศ. 2016 
บริษัท DeepMind ซึ่งเป็นบริษัทลูกของ Alphabet ก็พัฒนาโมเดลปัญญาประดิษฐ์ AlphaGo ที่สามารถเล่นหมากล้อมได้อย่างชาญฉลาด 
และก็เป็นปีเดียวกันกับที่ DeepMind ได้เริ่มต้นพัฒนา AlphaFold ซึ่งเป็นโมเดล ML สำหรับการทำนายโครงสร้างสามมิติของโปรตีน และในปี ค.ศ. 
2021 DeepMind ก็ได้ตีพิมพ์บทความที่นำเสนอ AlphaFold 2 ออกมาครับ\autocite{jumper2021} ซึ่งผู้เขียนขอแนะนำให้ลองอ่านบทความ%
งานวิจัยฉบับเต็มดู แต่ถ้าหากไม่มีเวลาอ่านหรือว่าอ่านแล้วแต่ยังไม่ค่อยเข้าใจก็สามารถดูวิดีโออธิบายบน YouTube ได้ โดยค้นหาวิดีโอที่ชื่อว่า 
\enquote{DeepMind's AlphaFold 2 Explained! AI Breakthrough in Protein Folding! What we know (\& what we don't)} 
ที่อธิบายโดย Yannic Kilcher หรือสแกน QR Code ตามภาพที่ \ref{fig:qr_code_alphafold}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.3\linewidth]{fig/qr_code_alphafold2_explained.png}
    \caption{ลิงก์วิดีโอ DeepMind's AlphaFold 2 Explained! AI Breakthrough in Protein Folding! What we know 
    (\& what we don't) \url{https://www.youtube.com/watch?v=B9PL__gVxLI}}
    \label{fig:qr_code_alphafold}
\end{figure}

ช่วงปลายปี ค.ศ. 2022 ทีม DeepMind ก็ได้สะเทือนวงการปัญญาประดิษฐ์อีกครั้งด้วยอัลกอริทึม ML แบบใหม่ที่สามารถหาอัลกอริทึมที่สามารถคูณ%
เมทริกซ์ได้โดยมีความเร็วมากกว่าอัลกอริทึมแบบดั้งเดิมที่ใช้กันมายาวนานกว่า 50 ปี โดยโมเดล ML ที่ทาง DeepMind ได้สร้างขึ้นมานั้นมีชื่อว่า 
AlphaTensor โดยใช้ Transformer\autocite{vaswani2017} เป็นโมเดลหลักในการฝึกสอน\footnote{โมเดลการเรียนรู้เชิงลึกแบบหนึ่งซึ่งใช้ 
Self-attention พัฒนาโดย Google Brain สำหรับงานทางด้านการประมวลผลภาษาธรรมชาติ (Natural Language Processing) หรือ 
NLP และเผยแพร่ในปี ค.ศ. 2017} โดยอัลกอริทึม ML ที่ถูกค้นพบโดย AlphaTensor สามารถทำการคูณเมทริกซ์ขนาด $4 \time 4$ 
ได้โดยใช้การคูณทั้งหมดแค่ 47 ครั้ง ซึ่งน้อยกว่าการใช้อัลกอริทึมของสตราซเซนแบบสองระดับ (Strassen's Two-level Algorithm) 
ซึ่งใช้การคูณทั้งหมด 49 ครั้ง\autocite{strassen1969}  และค่าความซับซ้อนเชิงการคำนวณ (Computational Complexity) 
ของอัลกอริทึมใหม่นี้อยู่ที่ประมาณ ${\mathcal{O}}({N}^{2.778})$ 

จากตัวอย่างข้างต้นนั้นเราสามารถสรุปได้อย่างไม่ต้องลังเลเลยว่า ML นั้นสามารถปฏิวัติวงการต่าง ๆ ได้อย่างน่าเหลือเชื่อ ไม่เพียงเฉพาะวงการ%
คณิตศาสตร์และวิทยาศาสตร์เท่านั้น แต่รวมไปถึงวงการอื่น ๆ ด้วยที่เทคนิคเหล่านี้เข้าไปมีบทบาท ซึ่งไม่เพียงแค่ในเฉพาะปัจจุบันเท่านั้นแต่ว่าใน%
อนาคตนั้นเราอาจจะได้เห็นสิ่งใหม่ ๆ ที่ ML นั้นสามารถสร้างสรรค์ขึ้นมาได้เอง

\begin{figure}[htbp]
    \centering
    \includegraphics[scale=1]{fig/ML-concept.pdf}
    \caption{แผนภาพเปรียบเทียบการทำงานของโปรแกรมแบบดั้งเดิมกับการเรียนรู้ของเครื่อง}
    \label{fig:ml_paradigm}
\end{figure}

แผนภาพที่ \ref{fig:ml_paradigm} แสดงการเปรียบเทียบอินพุต (Input) และเอาต์พุต (Output) ระหว่างโปรแกรมคอมพิวเตอร์ทั่วไปแบบ%
ดั้งเดิมที่เราเขียนโค้ดกันอยู่ในทุกวันนี้และโมเดลของปัญญาประดิษฐ์ โดยการเขียนโปรแกรมแบบทั่วไปนั้นเราจะต้องทำการเขียนโปรแกรมเริ่มต้นขึ้นมา%
และทำการป้อนอินพุตเข้าไปเพื่อให้ได้มาซึ่งเอาต์พุตหรือคำตอบที่เราต้องการ โดยกระบวนการของการเขียนโปรแกรมแบบดั้งเดิมนั้นจะเป็นกระบวนการ%
แบบที่ทำแล้วจบ อธิบายง่าย ๆ คือโปรแกรมของเราถูกกำหนดมาเพื่อรับอินพุตและคำนวณเอาต์พุตรูปแบบเดียว ซึ่งเราไม่สามารถนำโปรแกรมที่เขียน%
ขึ้นมานี้ไปใช้ต่อได้ (Non-transferable) แต่สำหรับกรณีของปัญญาประดิษฐ์หรือ ML นั้นจะตรงข้ามกันนั่นคือเราจะมีการป้อนทั้งอินพุตและเอาต์พุต%
เข้าไปให้กับปัญญาประดิษฐ์แล้วให้ปัญญาประดิษฐ์ทำการสร้างโปรแกรมหรือโมเดลโดยใช้เทคนิค ML ที่สามารถอธิบายความสัมพันธ์ของชุดข้อมูลที่มี%
ตัวแปรต้นหรือตัวแปรอิสระ (Independent Variable) และตัวแปรตาม (Dependent Variable) ได้ ซึ่งโมเดล ML ที่ถูกสร้างขึ้นมานี้สามารถ%
นำไปใช้งานต่อกับชุดข้อมูลอื่นได้ เราเรียกความสามารถนี้ของโมเดลว่าความสามารถในการส่งต่อหรือส่งผ่าน (Transferability)

%--------------------------
\section{เมื่อการเรียนรู้ของเครื่องมาเจอกับเคมี}
\label{sec:ml_meets_chem}
%--------------------------

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{fig/ml_rocket.png}
    \caption{เปรียบเทียบพลังงานที่ใช้ในการจำลองระบบโมเลกุลขนาดใหญ่ด้วยวิธี Molecular Dynamics กับพลังงานที่ใช้ในการส่งจรวด 
    Saturn V เพื่อไปโคจรรอบดวงจันทร์}
    \label{fig:ml_rocket}
\end{figure}

เคมีเป็นศาสตร์ที่เสมือนกับเป็นสะพานเชื่อมโยงศาสตร์อื่น ๆ เข้าด้วยกัน พูดง่าย ๆ คือเคมีเป็นสิ่งที่อยู่ตรงกลางระหว่างฟิสิกส์ ชีววิทยา และคณิตศาสตร์
นั่นก็เพราะว่าวิชาเคมีนั้นเป็นการบูรณาการทั้งสามสาขาเข้าด้วยกัน เราใช้ความรู้ทางฟิสิกส์โดยเฉพาะทฤษฎีกลศาสตร์ทั้งแบบดั้งเดิมและสมัยใหม่ในการ%
ทำความเข้าใจอนุภาคขนาดเล็ก อะตอม โมเลกุลอินทรีย์และอนินทรีย์ สารประกอบที่มีความซับซ้อน พอลิเมอร์ที่มีขนาดใหญ่ องค์ประกอบและหน่วย%
วัสดุต่าง ๆ รวมไปถึงสารชีวโมเลกุล เช่น โปรตีน, ลิพิด, และสารพันธุกรรม ซึ่งเป็นหน่วยย่อยขั้นพื้นฐานที่เป็นองค์ประกอบของสิ่งมีชีวิต 
โดยเราต้องใช้ความรู้ทางคณิตศาสตร์ในการแก้ปัญหาทางฟิสิกส์เชิงเคมีอีกด้วย

สำหรับปัญญาประดิษฐ์ซึ่งมี ML เป็นหัวใจสำคัญนั้นก็ถือว่าเป็นสาขาหนึ่งของสถิติเชิงข้อมูลและเกี่ยวข้องกับวิทยาการคอมพิวเตอร์ โดยการนำเทคนิค 
ML เข้ามาใช้ในการแก้ปัญหาบางอย่างทางเคมีนั้นถือว่าสมเหตุสมผลมาก นั่นก็เพราะว่านักเคมีมีข้อมูลทีได้จากการทดลองอย่างมากมายมหาศาล 
มีทั้งผลการทดลองที่เป็นบวกและผลการทดลองที่เป็นลบ ซึ่งข้อมูลเหล่านี้มีข้อมูลเชิงลึกที่สำคัญแฝงอยู่ ดังนั้น ML จึงเข้ามามีบทบาทอย่างมากในการสกัด 
(Extract) หรือเปิดเผยสิ่งที่ซ่อนอยู่ออกมาทำให้เราเข้าใจข้อมูลทางเคมีมากขึ้นและนำไปสู่การค้นพบหรือการทำนายสิ่งใหม่ ๆ ที่จะช่วยต่อยอดให้การ%
ทำงานวิจัยทางด้านเคมีนั้นเป็นไปอย่างรวดเร็วอย่างที่เรียกว่าก้าวกระโดดเลยทีเดียว\autocite{cartwright2020,zotero-817}

ภาพที่ \ref{fig:ml_rocket} แสดงการเปรียบเทียบพลังงานที่ใช้ในการจำลองระบบโมเลกุลขนาดใหญ่ด้วยวิธีพลวัติเชิงโมเลกุล (Molecular 
Dynamics หรือ MD) กับพลังงานที่ใช้ในการส่งจรวด Saturn V เพื่อไปโคจรรอบดวงจันทร์ โดยจะเห็นได้ว่าพลังงานที่ใช้ในการรัน MD Simulation 
นั้นเป็นหนึ่งในสามของพลังงานที่ใช้ในการส่งจรวด ถ้าหากเราการที่จะศึกษาโมเลกุลใหม่หรือปรับแก้พารามิเตอร์ของการคำนวณเราจะต้องรันการจำลอง 
MD ใหม่ทุกครั้งซึ่งสิ้นเปลืองพลังงานเป็นอย่างมาก ดังนั้น ML จึงเข้ามาบทบาทอย่างมากในเคมีเพราะว่าโมเดล ML นั้นสามารถนำไปใช้ในการศึกษา%
โมเลกุลอื่น ๆ ได้เพราะว่ามีคุณสมบัติของการส่งต่อความสามารถในการทำนาย (Transferability) นั่นเอง
\idxboth{พลวัติเชิงโมเลกุล}{Molecular Dynamics}

%--------------------------
\section{บทบาทของการเรียนรู้ของเครื่องต่อเคมีควอนตัม}
\label{sec:ml_in_qm}
%--------------------------

เคมีควอนตัม (Quantum Chemistry) เป็นแขนงหนึ่งของเคมีเชิงฟิสิกส์ (Physical Chemistry) ซึ่งเป็นการผสมผสานระหว่างกลศาสตร์ควอนตัม 
(Quantum Mechanics) และการศึกษาโครงสร้างเชิงอิเล็กทรอนิกส์ (Electronic Structure) ของอะตอมและโมเลกุลเข้าด้วยกัน 
ซึ่งจะเรียกอีกอย่างว่ากลศาสตร์ควอนตัมโมเลกุลก็ได้เช่นกัน (Molecular Quantum Mechanics) อธิบายได้ง่าย ๆ คือเป็นการนำความรู้ทาง%
กลศาสตร์ควอนตัมที่เป็นการศึกษาอันตรกิริยาระหว่างอนุภาคพื้นฐานในอะตอม (สนใจเฉพาะอิเล็กตรอนและโปรตอน) มาศึกษาคุณสมบัติโดยรวมของ%
โมเลกุลที่เราสนใจ ซึ่งนักวิทยาศาสตร์ได้ศึกษาและค้นคว้างานวิจัยศาสตร์ด้านนี้มากว่าหนึ่งศควรรษแล้วนับตั้งแต่ช่วงต้นปี ค.ศ. 1920 โดยได้มีการ%
พัฒนาทฤษฎีต่าง ๆ มากมาย แต่สิ่งที่ผู้เขียนคิดว่าน่าสนใจก็คือจุดเปลี่ยนสำคัญของเคมีควอนตัมยุคใหม่ (Modern Quantum Chemistry) นั่นคือ 
\enquote{ทฤษฎีฟังก์ชันนอลความหนาแน่น} หรือ \enquote{Density Functional Theory (DFT)}\autocite{kohn1996} 
ซึ่งถูกพัฒนาและใช้งานอย่างต่อเนื่องมามากกว่าครึ่งศตวรรษแล้ว โดยนักวิทยาศาสตร์ได้ใช้ DFT ในงานวิจัยทางด้านเคมี ฟิสิกส์ ชีวิทยาและวัสดุศาสตร์ 
ถ้าหากใครที่เคยเรียนวิชาเคมีเชิงฟิสิกส์หรือฟังการนำเสนอผลงานวิจัยตามงานประชุมวิชาการเคมีหรือฟิสิกส์ก็น่าจะเคยได้ยินชื่อทฤษฎีนี้กันมาบ้าง 
\idxboth{เคมีควอนตัม}{Quantum Chemistry}
\idxboth{ทฤษฎีฟังก์ชันนอลความหนาแน่น}{Density Functional Theory}
\idxboth{โครงสร้างเชิงอิเล็กทรอนิกส์}{Electronic Structure}

DFT เป็นทฤษฎีที่เรานำมาใช้ในการศึกษาคุณสมบัติของโมเลกุลไม่ว่าจะเป็นขนาดเล็ก อย่างเช่น โมเลกุลของสารประกอบอินทรีย์และอนินทรีย์ 
หรือจะเป็นโมเลกุลขนาดใหญ่ อย่างเช่น โปรตีน, วัสดุโลหะ และพอลิเมอร์ นั่นก็เพราะว่าการคำนวณด้วย DFT ให้ผลแม่นยำในระดับที่ยอมรับได้ 
(การพิจารณาความแม่นยำของวิธีการคำนวณนั้นขึ้นอยู่กับหลายปัจจัย) และใช้เวลาในการคำนวณที่ไม่นานมาก นั่นจึงทำให้ทฤษฎี DFT ได้รับการ%
ยกย่องเชิดชูเกียรติด้วยรางวัลโนเบลสาขาเคมีในปี ค.ศ. 1998 โดยผู้รับรางวัลได้แก่ ศาสตราจารย์ Walter Kohn (University of California, 
Santa Barbara, CA, USA) สำหรับการพัฒนาทฤษฎี DFT และศาสตราจารย์ John Pople (Northwestern University, Evanston, IL, 
USA) สำหรับการพัฒนาวิธีการคำนวณสำหรับเคมีควอนตัม\footnote{รายละเอียดของรางวัลโนเบลสาขาเคมี ปี ค.ศ. 1998 ดูได้ที่ 
\url{https://www.nobelprize.org/prizes/chemistry/1998/summary}} อย่างไรก็ตามในปัจจุบันก็ได้มีงานวิจัยที่ศึกษาทฤษฎี DFT 
แล้วพบว่าในความเป็นจริงนั้น DFT ไม่ได้ให้ผลการคำนวณที่แม่นยำสูงมากนักเมื่อเทียบกับวิธีฟังก์ชันคลื่นหรือ Wavefunction Theory (WFT)%
\autocite{korth2017,janesko2021} และยังไม่สามารถคำนวณคุณสมบัติของระบบบางระบบได้ จึงทำให้ในปัจจุบันนั้นได้มีการพัฒนาระเบียบวิธีใหม่ ๆ 
ขึ้นมาเพื่อปรับปรุงประสิทธิภาพหรือความสามารถของ DFT ให้เทียบเท่ากับวิธี WFT

ในขณะเดียวกันนั้น ML ก็ถูกนำมาใช้ประโยชน์ในงานวิจัยเคมีมานานกว่า 30 ปีแล้ว เนื่องจากในปัจจุบันนั้นเทคโนโลยีต่าง ๆ เช่น การประมวลผลขั้นสูง 
(High Performance Computing), การประมวลผลบนก้อนเมฆหรือคลาวด์ (Cloud Computing) และการ์ดจอ (Graphical Processing Unit 
หรือ GPU) ได้เข้ามามีบทบาทอย่างมากในวิทยาศาสตร์เชิงคำนวณ (Computational Science) โดยเฉพาะเคมีเชิงคำนวณ (Computational 
Chemistry) จึงทำให้มีจุดเปลี่ยนที่ทำให้ความสนใจของนักวิจัยในช่วง 10 ปีที่ผ่านมานี้ในหันมาทำงานวิจัยโดยใช้ ML กันมากขึ้น อีกเหตุผลหนึ่งก็%
คือในปัจจุบันเราสามารถศึกษาและใช้ง่าย ML ได้ง่ายขึ้นเมื่อเทียบกับในอดีต ทุกวันนี้เราไม่จำเป็นต้องมานั่งเขียนโค้ดเพื่อสร้างโมเดล ML แบบเริ่มจาก%
ศูนย์กันแล้ว ในปัจจุบันเรามีภาษาโปรแกรมที่ศึกษาและใช้งานได้ง่าย เช่น ภาษา Python และมีไลบรารี่ที่เราสามารถใช้งานได้ฟรีหรือนำมาพัฒนาต่อได้ 
(Open-source) มากมาย เช่น Scikit-learn\autocite{scikit-learn}, TensorFlow\autocite{tensorflow2015-whitepaper}, 
PyTorch\autocite{NEURIPS2019_9015}, Flux\autocite{innes2018} หรือแม้แต่ Matlab\autocite{MATLAB:2010} ที่ก็มีฟังก์ชัน%
สำเร็จรูปมาให้เราใช้งานได้เลย ซึ่งทำให้เราสามารถเลือกใช้โมเดล ML ต่าง ๆ ได้ตามต้องการ
\idxboth{เคมีเชิงคำนวณ}{Computational Chemistry}

ผู้เขียนขอยกตัวอย่างหัวข้องานวิจัยหนึ่งที่ตอนนี้กำลังมาแรง (อย่างน้อย ๆ ก็ ณ วันที่ผู้เขียนกำลังเขียนหนังสือเล่มนี้) นั่นคือการพัฒนาโมเดล ML 
เพื่อเรียนรู้ฟังก์ชันการแลกเปลี่ยนและสหสัมพันธ์ (Exchange-Correlation Functional หรือ XC)\autocite{balabin2009a} ซึ่ง XC 
นี้ถือได้ว่าเป็นอินพุตที่สำคัญที่สุดของ DFT ในการนำไปศึกษาระบบต่าง ๆ ทางเคมีให้ได้หลายระบบ เช่น สารประกอบที่มีขนาดเล็กและใหญ่ 
ซึ่งเราเรียกสิ่งที่มีความสามารถในการทำอะไรได้หลาย ๆ อย่างว่าสารพัดประโยชน์ (General Purpose) โดยนำมาใช้งานได้ทั่วไป หรืออาจจะเรียก%
อีกอย่างว่าเป็นสิ่งที่มีความสากล (Universality) นั่นเอง ถ้าหากเราพัฒนาโมเดล XC ด้วย ML ที่มีประสิทธิภาพที่ดีมาก ๆ ได้สำเร็จ เราก็จะมีโมเดล 
XC ที่สามารถนำไปใช้ในการทำนายหรือคำนวณคุณสมบัติของโมเลกุล สารประกอบและวัสดุทางเคมีได้อย่างถูกต้องและแม่นยำ แต่ในความเป็นจริงนั้น 
XC ก็เปรียบเสมือนเป็นกล่องดำ (Black Box) ของ DFT เพราะว่าไม่มีใครที่รู้หน้าตาสมการหรือผลเฉลยทั่วไปที่แน่นอนของ XC เพราะว่าเป็นเทอม%
ที่อธิบายอันตรกิริยาระหว่างอิเล็กตรอน ดังนั้นนับตั้งแต่อดีตจนถึงปัจจุบัน เราจึงทำได้เพียงแค่หารูปแบบโดยใช้วิธีการประมาณเท่านั้น ตรงจุดนี้เองที่ ML 
ก็เข้ามามีบทบาทและทำให้งานวิจัยในช่วงระยะหลังนี้มีการพัฒนา ML เยอะมาก เพราะเป็นการประมาณค่าแบบหนึ่งที่ใช้หลักการทางสถิติเข้ามาช่วยใน%
การหาความสัมพันธ์ระหว่างของสองสิ่งซึ่งให้ความแม่นยำสูงและไม่สิ้นเปลืองการคำนวณ ถึงแม้ว่าตอนนี้การนำ ML เข้ามาช่วยในการทำวิจัยทางด้าน%
เคมีควอนตัม (และสาขาอื่น ๆ ด้วย) จะยังอยู่ในขั้นของการพัฒนา แต่สิ่งหนึ่งที่เราเห็นได้เลยก็คือ ML สามารถช่วยลดระยะเวลาในคำนวณคุณสมบัติ%
เชิงอิเล็กทรอนิกส์ (Electronic Properties) ของโมเลกุลอย่างเห็นได้ชัด
\idxboth{ฟังก์ชันการแลกเปลี่ยนและสหสัมพันธ์}{Exchange-Correlation Functional}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{fig/qm_scaling.png}
    \caption{แผนภาพแสดง Scaling ของวิธีทางเคมีควอนตัม (เครดิตภาพ: https://www.chemistryworld.com)}
    \label{fig:qm_scaling}
\end{figure}

\begin{table}[htbp]
    \centering
    \caption{ตารางเปรียบเทียบความซับซ้อนเชิงคำนวณของวิธีทางเคมีควอนตัม\autocite{rupp2015} โดย $N$ คือจำนวนของอิเล็กตรอนหรือ%
    จำนวนของ Basis function}
    \label{tab:qm_complx}
    \small
    \begin{tabular}{lll}\toprule
    \textbf{ตัวย่อ} &\textbf{วิธี} &\textbf{Runtime} \\\midrule
    FCI &Full Configuration Interaction (CISDTQ) &$\mathcal{O}(N^{10})$ \\
    CC &Coupled Cluster (CCSDT) &$\mathcal{O}(N^{8})$ \\
    CC &Coupled Cluster (CCSD(T)) &$\mathcal{O}(N^{7})$ \\
    CC &Coupled Cluster (CCSD) &$\mathcal{O}(N^{6})$ \\
    FCI &Full Configuration Interaction (CISD) &$\mathcal{O}(N^{6})$ \\
    MP2 &M$\o$llor-Plesset second order perturbation theory &$\mathcal{O}(N^{5})$ \\
    QMC &Quantum Monte Carlo &$\mathcal{O}(N^{3}) - \mathcal{O}(N^{4})$ \\
    HF &Hartree-Fock &$\mathcal{O}(N^{3}) - \mathcal{O}(N^{4})$ \\
    DFT &Density Functional Theory (Kohn-Sham) &$\mathcal{O}(N^{3})$ \\
    TB &Tight Binding &$\mathcal{O}(N^{3})$ \\
    MM &Molecular Mechanics &$\mathcal{O}(N^{2})$ \\
    \bottomrule
    \end{tabular}
\end{table}

ตารางที่ \ref{tab:qm_complx} แสดงค่าความซับซ้อนของการคำนวณ (Compuational Complexity) ของแต่ละวิธี โดยจะเห็นได้ว่าวิธี DFT 
นั้นมีความซับซ้อนคือ $\mathcal{O}(N^{3})$ นั่นคือมันเป็นสัดส่วนโดยตรงกับจำนวนของอิเล็กตรอนของระบบ ($N$) ยกกำลังสาม ซึ่งมาจาก%
การที่เราจะต้องทำการทำให้ Hamiltonian เกิดเมทริกซ์รูปทแยง (Diagonalization)\footnote{เป็นวิธีการเปลี่ยนฐานของปริภูมิเวกเตอร์%
เพื่อให้ได้เมทริกซ์การแปลงเชิงเส้นที่อยู่ในรูปเมทริกซ์ทแยง เพื่อที่จะนำไปคำนวณในขั้นตอนต่อไปได้อย่างสะดวกมากขึ้น} ซึ่งความซับซ้อนของการทำ 
Diagonalization สำหรับเมทริกซ์จตุรัสขนาด $n \times n$ คือ 
$\mathcal{O}(n^{3})$

\begin{adjustwidth}{-2.5 cm}{-2.5 cm}
    \centering
    \begin{threeparttable}[htbp]
    \caption{ตารางเปรียบเทียบความซับซ้อนเชิงคำนวณของวิธีทางเคมีควอนตัม\autocite{zotero-328} โดย $n$ คือจำนวนของข้อมูล, $p$ 
    คือจำนวน Feature, $n_{trees}$ คือจำนวนของต้นไม้ (Trees), $n_{sv}$ คือจำนวนของ Support Vectors, $n_{L_{i}}$ 
    คือจำนวนของ Neuron หรือ Node ของชั้นที่ $i$ และ $t$ คือจำนวนของ Epochs ที่ใช้ในการฝึกฝนโมเดล}
    \label{tab:ml_complx}
    \small
    \begin{tabular}{lll}\toprule
    \multirow{2}{*}{\textbf{อัลกอริทึม}} &\multicolumn{2}{c}{\textbf{Runtime}} \\\cmidrule{2-3}
    &\textbf{การฝึกฝนโมเดล} &\textbf{การทำนายเอาต์พุต}\\\midrule
    Decision Tree &$\mathcal{O}(n^{2}p)$ &$\mathcal{O}(p)$ \\
    Random Forest &$\mathcal{O}(n^{2}pn_{trees})$ &$\mathcal{O}(pn_{trees})$ \\
    Gradient Boosting ($n\_{trees}$) &$\mathcal{O}(npn_{trees})$ &$\mathcal{O}(pn_{trees})$ \\
    Linear Regression &$\mathcal{O}(p^{2}n+p^{3})$ &$\mathcal{O}(p)$ \\
    SVM (Kernel) &$\mathcal{O}(n^{2}p+n^{3})$ &$\mathcal{O}(n_{sv}p)$ \\
    Neural Network &$\mathcal{O}(npt*(n_{L_{1}}n_{L_{2}}+ n_{L_{2}}n_{L_{3}} + \dots)$ &$\mathcal{O}(pn_{L_{1}} 
    + n_{L_{1}}n_{L_{2}}+ \dots)$ \\
    \bottomrule
    \end{tabular}
\end{threeparttable}
\end{adjustwidth}

ตารางที่ \ref{tab:ml_complx} แสดงค่าความซับซ้อนของการคำนวณของอัลกอริทึม ML แบบต่าง ๆ เช่นเดียวกับตารางก่อนหน้านี้ 
โดยอัลกอริทึมที่แสดงนั้นถูกใช้กับโจทย์ปัญหา Classification และ Regression (ยกเว้น Linear Regression ที่ใช้สำหรับ Regression 
เท่านั้น) จะเห็นได้ว่าความซับซ้อนของวิธี ML นั้นจะขึ้นอยู่กับจำนวนของข้อมูลและจำนวน Feature ของข้อมูลแต่ละตัวเป็นหลัก ยกเว้นกรณีของ%
โมเดล Neural Network ซึ่งเราสนใจเฉพาะการเรียนรู้เชิงลึก (Deep Learning) เท่านั้นที่ความซับซ้อนของโมเดลจะขึ้นอยู่กับจำนวนรอบที่ใช้%
ในการฝึกสอนโมเดลและจำนวนชั้นของโครงข่าย

ถ้าหากเปรียบเทียบแล้วจะพบว่าวิธี ML นั้นมีความซับซ้อนน้อยกว่าวิธี QM อย่างมีนัยสำคัญ อย่างน้อย ๆ ก็ในระดับหลายเท่าตัว และยิ่งไปกว่านั้น
ความซับซ้อนเชิงการคำนวณในการทำนายค่าเอาต์พุตของโมเดลที่ผ่านการฝึกสอนมาแล้วนั้นต่ำมาก ซึ่งโดยส่วนใหญ่แล้วจะอยู่ในรูปของผลคูณ%
เชิงเส้นแบบดีกรี 1 ระหว่างจำนวนของข้อมูลกับจำนวนของ Feature นี่จึงเป็นเหตุผลที่ทำให้งานวิจัยทางด้านเคมี โดยเฉพาะด้าน QM ในช่วงระยะเวลา
10 ปีที่ผ่านมานั้น นักวิจัยเริ่มให้ความสนใจในการประยุกต์ใช้ ML เพื่อมาใช้ในการสร้างโมเดลสำหรับประมาณค่าหรือทำนายค่าต่าง ๆ ทางควอนตัม 
นั่นก็เพราะ ML เป็นวิธีที่สิ้นเปลืองน้อยกว่า

%--------------------------
\section{ทักษะที่จำเป็นสำหรับผู้เริ่มต้นศึกษาการเรียนรู้ของเครื่อง}
\label{sec:skills_for_ml}
%--------------------------

การมีความรู้พื้นฐานก่อนเริ่มศึกษา ML อย่างจริงจังนั้นมันเป็นสิ่งสำคัญ ผู้เขียนได้สรุป 5 สิ่งสำคัญที่ผู้ที่เริ่มต้นศึกษาควรจะต้องรู้ ดังต่อไปนี้

\begin{enumerate}
    \item \textbf{พีชคณิตเชิงเส้นและแคลคูลัสแบบหลายตัวแปร} : ทั้งสองวิชานี้ถือว่าเป็นรากฐานของ ML เลยก็ว่าได้ 
    เพราะว่าโมเดลทุกรูปแบบของ ML นั้นต่างก็ล้วนแต่เป็นคณิตศาสตร์ ถ้าหากเราต้องการที่จะพัฒนาอัลกอริทึมใหม่ ๆ 
    หรือปรับปรุงอัลกอริทึมที่มีอยู่แล้ว เราจะต้องอาศัยความรู้พีชคณิตเชิงเส้น (เวกเตอร์และเมทริกซ์) และแคลคูลัส (การหาอนุพันธ์) 
    แต่ถ้าหากว่าเราเน้นไปทางสายแอพพลิเคชัน เราก็อาจจะไม่จำเป็นต้องรู้แบบลึกหรือละเอียดมากก็ได้ เพราะว่าในปัจจุบันมีเครื่องมือและไลบรารี่%
    สำเร็จรูปให้เราเลือกใช้มากมาย
    
    \item \textbf{สถิติ} : เนื่องจากว่าในขั้นตอนก่อนที่จะเริ่มสร้างและเทรนโมเดล ML นั้น เราจะต้องใช้เวลาส่วนใหญ่ 
    (อาจจะมากถึง 80\%) ไปกับการรวบรวมข้อมูล ทำความสะอาดข้อมูล การศึกษาการกระจายตัวของข้อมูล การตั้งและทดสอบสมมติฐาน 
    การทำการถดถอย (Regression) การแยกประเภท (Classification) เราจึงจำเป็นจะต้องใช้สถิติเข้ามาช่วยเพื่อให้เข้าใจถึงรายละเอียด
    ของชุดข้อมูลที่เรากำลังจะเล่นกับมัน ยิ่งเข้าใจข้อมูลมากเท่าไหร่ ยิ่งช่วยให้เราสามารถเลือกใช้โมเดล ML ได้เหมาะสมเท่านั้น 
    
    \item \textbf{โปรแกรมมิ่ง} : สิ่งสำคัญลำดับถัดมาคือทักษะในการเขียนโปรแกรมหรือเขียนโค้ด ถึงแม้ว่าเราจะมีความรู้ด้านทฤษฎีที่แม่นยำ 
    แต่ถ้าหากเราไม่สามารถเขียนโปรแกรมได้ แล้วก็ไม่สามารถสร้างโมเดลหรือนำ ML มาใช้งานจริงได้เลย ดังนั้นเราควรจะต้องเรียนรู้การเขียนโปรแกรม
    ให้ได้อย่างน้อยสัก 1 ภาษา ซึ่งภาษาที่ได้รับความนิยมมากที่สุดสำหรับงานทางด้านวิทยาศาสตร์ข้อมูล ณ ตอนนี้คือภาษา Python 
    นั่นก็เพราะตัวภาษาเองมีไวยากรณ์ (Syntax) ที่เข้าใจง่าย มีไลบรารี่ให้เลือกใช้เยอะ มี Community ที่ใหญ่มาก ไม่ต้องกลัวเลยว่าถ้าหากมี%
    ปัญหาเกี่ยวกับการเขียน Python แล้วจะไม่มีคนช่วยหรือหาวิธีแก้ปัญหาไม่ได้ เว็บไซต์ที่มีการถามตอบคำถามเกี่ยวกับการเขียนโปรแกรมที่ได้รับ%
    ความนิยมเป็นอันดับหนึ่งก็คือ Stack Overflow (\url{https://stackoverflow.com})
    
    \item \textbf{แนวคิดของ ML} : แนวคิดหรือ Concept ทางด้าน ML (วิทยาศาสตร์ข้อมูล) เป็นสิ่งที่สำคัญมากเช่นเดียวกัน
    เราควรจะทราบคำศัพท์เฉพาะทางและความหมาย (Terminology) ประเภทของ ML แนวทางการนำ ML มาใช้ (Best Practice)
    
    \item \textbf{ฝึกทำโจทย์จริง} : ตัวช่วยที่ดีที่สุดให้ทำเราเรียนรู้ ML ได้อย่างรวดเร็วนั่นก็คือการฝึกฝน ทั้งการเขียนโค้ดและการฝึกวิเคราะห์ 
    ลองหาโจทย์จริง ๆ มาฝึกทำ หรืออาจจะลองเก็บเกี่ยวประสบการณ์โดยเข้าร่วมการแข่งขันวิทยาศาสตร์ข้อมูล ซึ่งในปัจจุบันก็มีการจัดแข่งขันบ่อยมาก ๆ 
    เรียกได้ว่ามีสนามให้ได้ฝึกฝนวิทยายุทธเป็นพัน ๆ เลย เช่น Kaggle (\url{https://www.kaggle.com/competitions}) และ
    AIcrowd (\url{https://www.aicrowd.com}) 
\end{enumerate}

%--------------------------
\section{แนวทางสำหรับการศึกษาการเรียนรู้ของเครื่อง}
\label{sec:learn_ml}
%--------------------------

ผู้เขียนได้สรุปแนวทางศึกษา ML สำหรับงานวิจัยทางด้านเคมี (เน้นเคมีควอนตัม) สำหรับผู้เริ่มต้นตามด้านล่างต่อไปนี้

\begin{enumerate}
    \item ฝึกเขียนภาษาคอมพิวเตอร์ให้คล่อง โดยภาษาที่ผู้เขียนแนะนำคือภาษา Python (เวอร์ชั่น 3.6 เป็นต้นไป) โดยสามารถเรียนได้จากชุด%
    วิดีโอที่ผู้เขียนได้จัดทำไว้ \enquote{Python for Scientific Computing - ไพธอนสำหรับการคำนวณทางวิทยาศาสตร์} ซึ่งเน้นไปที่%
    การเขียน Python สำหรับงานทางด้านวิทยาศาสตร์เชิงคำนวณ โดยดูได้บน YouTube\footnote{% 
    \url{https://youtube.com/playlist?list=PLt-twymrmZ2eUPDfuXP6A7fbiCZygd-sa}}

    \item เริ่มจากปรับพื้นฐานพีชคณิตเชิงเส้น (โดยเน้นไปที่เมทริกซ์) และแคลคูลัสแบบหลายตัวแปร เช่น การหาอนุพันธ์ย่อยและเวกเตอร์แคลคูลัส 
    รวมไปถึงวิธีวิเคราะห์ทางสถิติ
    
    \item ดูวิดีโอบน YouTube ที่อธิบายปัญญาประดิษฐ์เบื้องต้นตาม QR Code หรือลิงก์ในภาพที่ \ref{fig:qr_code_intro_ml}
    
    \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.3\linewidth]{fig/qr_code_intro_ml.png}
        \caption{ลิงก์วิดีโอ Machine Learning Basics | What Is Machine Learning? | Introduction To Machine 
        Learning \url{https://www.youtube.com/watch?v=ukzFI9rgwfU}}
        \label{fig:qr_code_intro_ml}
    \end{figure}

    หลังจากนั้นให้เรียนคอร์ส ML โดยคอร์สที่ผมแนะนำคือคอร์สออนไลน์ของศาสตราจารย์ Andrew Ng (Stanford University) บน Coursera 
    โดยมีสองคอร์สหลักคือ 
    \begin{enumerate}
        \item Machine Learning Specialization เป็นคอร์ส ML ที่ได้รับความนิยมมากที่สุดในโลก%
        \footnote{\url{https://www.coursera.org/specializations/machine-learning-introduction}}
        \item Deep Learning Specialization เป็นคอร์สที่ได้รับความนิยมไม่แพ้กัน โดยจะเน้นไปที่ Neural Network%
        \footnote{\url{https://www.coursera.org/specializations/deep-learning}}
    \end{enumerate}

    \noindent และคอร์สของ Stanford University ซึ่งมีศาสตราจารย์ Andrew Ng นำทีมสอนเช่นเดียวกัน
    \begin{enumerate}
        \item CS229: Machine Learning%
        \footnote{\url{https://cs229.stanford.edu}}
        \item CS230: Deep Learning%
        \footnote{\url{https://cs230.stanford.edu}}
    \end{enumerate}

    
    \item ทำแบบฝึกหัดตามหนังสือ \enquote{Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: 
    Concepts, Tools, and Techniques to Build Intelligent Systems} และหนังสือ \enquote{Python Machine Learning} 
    เพื่อจะได้ทำความคุ้นเคยกับ Framework ในการเขียนโค้ด ML และ Neural Network
    
    \item ศึกษาการประยุกต์ ML และ Neural Network สำหรับเคมีด้วยเว็บไซต์ \url{https://dmol.pub} ที่จัดทำโดยกลุ่มวิจัยของ%
    ศาสตราจารย์ Andrew White (University of Rochester) ซึ่งจะมีโจทย์ทางเคมีและโค้ดให้ฝึกเขียนตาม เช่น การทำนายคุณสมบัติที่%
    สำคัญและการทำนายพลังงานรวมของโมเลกุล
    
    \item ทบทวนงานวิจัย (Literature Review) ในวารสารวิชาการที่อ่านได้ง่ายและไม่ลงรายละเอียดเชิงเทคนิคมากเกินไป เช่น Chemical 
    Reviews หรือ Science Advances ที่เกี่ยวกับ ML สำหรับเคมีควอนตัมและเคมีสาขาอื่น ๆ
    
    \item เลือกอ่านบทความงานวิจัยจากวารสารเฉพาะทางเน้นไปที่เคมีทฤษฎีและการประยุกต์ โดยเลือกหัวข้องานวิจัยเคมีที่เราสนใจและต้องการ%
    นำ ML ไปประยุกต์ใช้กับหัวข้อนั้น ๆ
\end{enumerate}

อย่างไรก็ตาม แนวทางทั้ง 6 ข้อตามด้านบนนั้นเป็นความคิดเห็นส่วนตัวของผู้เขียนซึ่งอ้างอิงตามประสบการณ์จริง นอกจากแหล่งความรู้ที่ผู้เขียนได้%
แนะนำไว้แล้วจริง ๆ ยังมีแหล่งความรู้อื่น ๆ อีกมากมายที่ผู้อ่านสามารถศึกษาตามได้ด้วยตัวเอง

%--------------------------
\section{คำศัพท์เฉพาะทางด้านการเรียนรู้ของเครื่อง}
\label{sec:ml_term}
%--------------------------

\begin{description}[style=nextline]
    \item[Accuracy] ค่าความถูกต้องของการทำนายของโมเดล ส่วนใหญ่เรามักจะรายงานค่าความถูกต้องเป็นเปอร์เซ็นต์
    \idxboth{ค่าความถูกต้อง}{Accuracy}

    \item[Algorithm] วิธีหรือขั้นตอนกระบวนการคิดคำนวณทางคณิตศาสตร์เพื่อให้ได้ผลลัพธ์ออกมา
    \idxboth{อัลกอริทึม}{Algorithm}

    \item[Attribute] ปริมาณที่ได้จากการสังเกตซึ่งบ่งบอกถึงคุณลักษณะของสิ่งที่สนใจ เช่น สี, ขนาด, และความสูง พูดง่าย ๆ คือถ้าเป็น%
    ชุดข้อมูล Attribute ก็คือชื่อของแต่ละคอลัมน์นั่นเอง
    \idxboth{คุณลักษณะ}{Attribute}

    \item[Categorical Variables] ตัวแปรจัดกลุ่ม ไม่มีความต่อเนื่อง เป็นข้อมูลประเภทแบบแยกออกจากกันและไม่ขึ้นต่อค่าอื่น ๆ เช่น 
    เพศ เชื้อชาติ พันธ์สุนัข ชนิดของผลไม้ ชนิดของหมู่ฟังก์ชันในโมเลกุล
    \idxboth{ตัวแปรจัดกลุ่ม}{Categorical Variables}

    \item[Classification] การจำแนกข้อมูลหรือการทำนายค่าที่มีความไม่ต่อเนื่อง เช่น ประเภทของยานพาหนะ ชนิดของผลไม้
    \idxboth{การจำแนก}{Classification}
 
    \item[Clustering] การจัดกลุ่มข้อมูล
    \idxboth{การจัดกลุ่ม}{Clustering}

    \item[Confusion matrix] เมทริกซ์ที่แสดงการประเมินผลลัพธ์ของการทำนาย
    \begin{itemize}
        \item True Positives (TP): ทำนายว่าจริง และสิ่งที่เกิดขึ้นก็จริง
        
        \item True Negatives (TN): ทำนายว่าไม่จริง และสิ่งที่เกิดขึ้นก็ไม่จริง
        
        \item False Positives (FP): ทำนายว่าจริง แต่สิ่งที่เกิดขึ้นคือไม่จริง
        
        \item False Negatives (FN): ทำนายว่าไม่จริง แต่สิ่งที่เกิดขึ้นคือจริง
    \end{itemize}
    \idxen{Confusion matrix}

    \item[Continuous Variables] ตัวแปรต่อเนื่อง เป็นตัวแปรเชิงปริมาณที่มีค่าในช่วงที่กำหนด เช่น น้ำหนัก จำนวนรถ ความยาวพันธะ
    \idxboth{ตัวแปรต่อเนื่อง}{Continuous Variables}

    \item[Convergence] สถานะของโมเดลเมื่อการเปลี่ยนของค่า Loss ระหว่าง Interation มีขนาดน้อยมาก ๆ
    \idxboth{การลู่เข้า}{Convergence}

    \item[Descriptor] วิธีที่ใช้ในการแปลงข้อมูล เช่น ข้อมูลของโครงสร้างโมเลกุล ให้เป็นข้อมูลเวกเตอร์ที่เป็น Feature
    \idxen{Descriptor}

    \item[Dataset หรือ Data Set] ชุดข้อมูลที่มีคุณสมบัติเหมือนกันโดยถูกจัดเป็นชุดให้ถูกต้องตามลักษณะโครงสร้างข้อมูล
    \idxboth{ชุดข้อมูล}{Dataset}

    \item[Epoch] จำนวนครั้งหรือจำนวนรอบที่อัลกอริทึมมองเห็นหรือได้รับชุดข้อมูลทั้งหมดเข้ามาเพื่อทำการเรียนรู้
    \idxen{Epoch}

    \item[Extrapolation] เป็นการทำนายที่อยู่นอกเหนือจากชุดข้อมูลที่ใช้ในการฝึกสอนโมเดล
    \idxen{Extrapolation}

    \item[Feature] คุณลักษณะเฉพาะของสิ่งที่สนใจ โดยเป็นข้อมูลแบบ 1 มิติที่ถูกสร้างโดย Descriptor
    \idxboth{คุณลักษณะเฉพาะ}{Feature}

    \item[Hyperparameter] พารามิเตอร์ขั้นสูงที่กำหนดคุณสมบัติของโมเดล เช่น ความเร็วในการเรียนรู้ ความซับซ้อนของโมเดล
    ซึ่งผู้ใช้งานจะต้องทำการกำหนดพารามิเตอร์เหล่านี้ก่อนทำการสร้างหรือฝึกสอนโมเดล
    \idxboth{ไฮเปอร์พารามิเตอร์}{Hyperparameter}

    item[Input] อินพุตเป็นข้อมูลที่เรานำเข้าหรือป้อนเข้าไปให้กับโปรแกรมคอมพิวเตอร์
    \idxboth{อินพุต}{Input}

    \item[Learning Rate] อัตราเร็วในการเรียนรู้ของโมเดล หรือในทางทฤษฎีคือขนาดของก้าวในการปรับปรุง (Update Step) ในกระบวนการ 
    Optimization โดยการใช้อัลกอริทึม เช่น Gradient Descent
    \idxboth{อัตราเร็วในการเรียนรู้}{Learning rate}

    \item[Loss] ค่าความคลาดเคลื่อนหรือความแตกต่างระหว่างค่าที่ได้จากการทำนาย (Prediction) และค่าอ้างอิง (Ground Truth หรือ 
    Reference) ยิ่ง Loss มีค่าน้อย หมายความว่าโมเดลของเรายิ่งมีประสิทธิภาพสูง โดยค่า Loss จะถูกคำนวณในระหว่างการฝึกสอนโมเดล
    \idxboth{ค่่าความคลาดเคลื่อน}{Loss}

    \item[Model] ชุดคำสั่งหรือโปรแกรมที่ถูกสร้างขึ้นมาโดยมีความสามารถในการคำนวณ ประมวลผลและตัดสินใจ
    \idxboth{แบบจำลอง}{Model}

    \item[Noise] ข้อมูลที่มีความผิดปกติและไม่มีความเกี่ยวข้องกับข้อมูลที่เราสนใจ รวมไปถึงค่าที่เกิดจากการสุ่ม (Randomness)

    \item[Normalization] การทำให้เป็นปกติ เป็นการกำหนดหรือบังคับค่าของน้ำหนัก (Weights) ในการทำ Regression เพื่อป้องกันปัญหา
    Overfitting (การ Fit ข้อมูลที่ดีเกินไป) และเพิ่มความเร็วในการคำนวณ
    \idxboth{การทำให้เป็นปกติ}{Normalization}

    \item[Outlier] ค่าที่ผิดปกติไปจากข้อมูลตัวอื่นในชุดข้อมูล
    \idxen{Outlier}

    \item[Output] เอาต์พุตเป็นข้อมูลที่ถูกส่งออกมาจากโปรแกรมคอมพิวเตอร์
    \idxboth{เอาต์พุต}{Output}

    \item[Overfitting] คือการที่โมเดลที่ถูกฝึกสอนด้วยชุดข้อมูล Training Set มีค่าความถูกต้องในการบ่งบอกคลาสเป้าหมายสูง 
    แต่เมื่อนำไปใช้กับข้อมูลทดสอบ Test Set กลับได้ค่าความถูกต้องต่ำ กล่าวอีกนัยหนึ่งคือตัวโมเดลที่ได้สามารถเรียนรู้ข้อมูลจาก Training Set 
    ได้ดีมาก แต่ไม่สามารถนำไปใช้กับข้อมูลใหม่ที่ไม่เคยพบมาก่อน (Unknown Data) ได้ดี
    \idxen{Overfitting}

    \item[Parameter] คุณสมบัติของข้อมูลที่ถูกเรียนรู้โดยโมเดลปัญญาประดิษฐ์ โดยพารามิเตอร์จะถูกปรับให้มีความเหมาะสมตามอัลกอริทึมที่ใช้
    เช่น Optimization ตัวอย่างของพารามิเตอร์มีดังนี้
    \begin{itemize}
        \item น้ำหนัก (Wegiths) ในเทคนิค Neural Network
        
        \item Support Vectors ในเทคนิค Support Vector Machine
        
        \item ค่าสัมประสิทธิ์ (Coefficients) ในเทคนิค Linear Regression
    \end{itemize}
    \idxboth{พารามิเตอร์}{Parameter}

    \item[Precision] ความแม่นยำของการทำนาย มีสมการในการคำนวณดังนี้
    \begin{equation}\label{eq:precision}
        P = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
    \end{equation}

    \item[Prediction] กระบวนการทำนายค่าของโมเดลโดยจะทำนายค่าเอาต์พุตของข้อมูลใหม่ที่ถูกป้อนเข้าไป
    \idxboth{การทำนาย}{Prediction}

    \item[Regression]  การทำนายค่าที่มีความต่อเนื่อง เช่น ราคาสินค้า ปริมาณน้ำมัน ถ้าในบริบทของเคมีก็จะเป็นคุณสมบัติของโมเลกุล 
    เช่น พลังงานภายในของโมเลกุล, พลังงานอิสระของโมเลกุล และพลังงานกระตุ้น
    \idxen{Regression}

    \item[Regularization] การทำให้ถูกต้อง เป็นเทคนิคสำหรับการแก้ปัญหา Overfitting โดยการเพิ่มพจน์พิเศษที่มีความซับซ้อนเข้าไปใน 
    Loss function โดยเทคนิคนี้มีประโยชน์อย่างมากในการสร้างโมเดลที่มีความซับซ้อน
    \idxboth{การทำให้ถูกต้อง}{Regularization}

    \item[Reinforment Learning] การเรียนรู้แบบเสริมแรง 
    \idxboth{การเรียนรู้แบบเสริมแรง}{Reinforment Learning}

    \item[Representation] Feature ของโมเลกุลในรูปแบบสัญลักษณ์ (Symbolic) เช่น SMILES, InChI, สูตรโมเลกุล
    \idxen{Representation}

    \item[Segmentation] กระบวนการหรือขั้นตอนการแบ่งส่วนของชุดข้อมูลออกเป็นหลาย ๆ ชุดข้อมูลย่อย
    \idxen{Segmentation}

    \item[Specificity] ความจำเพาะเจาะจง เป็นพารามิเตอร์ที่วัเประสิทธิภาพของโมเดลในการจำแนกกรณีที่เป็นเท็จหรือไม่เป็นจริง (Negative)
    กล่าวอีกอย่างคือ เมื่อคำตอบคือ Negative พารามิเตอร์ตัวนี้จะบอกเราว่าการทำนายของโมเดลของเรานั้นถูกต้องมากน้อย (บ่อย) แค่ไหน
    โดยมีสมการที่ในการคำนวณคือ
    \begin{equation}\label{eq:specficity}
        S = \frac{\text{True Negatives}}{\text{True Negatives} + \text{False Positives}}
    \end{equation}
    \idxboth{ความจำเพาะเจาะจง}{Specificity}

    \item[Supervised Learning] การเรียนรู้ของโมเดลแบบมีผู้สอน (Output)
    \idxboth{การเรียนรู้แบบมีผู้สอน}{Supervised Learning}

    \item[Target / Output / Class / Label] คำตอบหรือเป้าหมายที่ต้องการคำนวณ (Calculate) ประมาณค่า (Approximate) 
    หรือทำนาย (Predict)
    \idxen{Target}
    \idxen{Output}
    \idxen{Class}
    \idxen{Label}

    \item[Test Set] ชุดข้อมูลที่ใช้ทดสอบความถูกต้องและแม่นยำของ Model
    \idxboth{ชุดข้อมูล!ชุดข้อมูลสำหรับการทดสอบ}{Test Set}

    \item[Training] กระบวนการสร้างและฝึกสอนโมเดลโดยใช้ Training set 
    \idxboth{การฝึกสอน}{Training}

    \item[Training Set] ชุดข้อมูลที่นำมาใช้ในการสอนคอมพิวเตอร์เพื่อสร้าง Model
    \idxboth{ชุดข้อมูล!ชุดข้อมูลสำหรับการฝึกสอน}{Training Set}

    \item[Transfer Learning] การเรียนรู้แบบส่งต่อ เป็นการนำโมเดล ML ที่ผ่านการฝึกสอนแล้วและสามารถทำงานอย่างหนึ่งได้อยู่แล้วมา%
    ฝึกสอนอีกครั้งหนึ่งเพื่อให้สามารถทำงานที่สองได้ โดยวิธีการทำ Transfer Learning ก็คือเรานำค่าพารามิเตอร์ที่ถูกปรับโดยผ่านการฝึกสอนแล้ว
    นำมาใช้ต่อในการทำนายค่าอื่น ๆ นั่นเอง ตัวอย่างเช่นถ้าเป็น Neural Network พารามิเตอร์ที่เรามาสามารถนำมาใช้ได้ก็จะเป็นน้ำหนัก (Weights) 
    ของแต่ละ Layer เป็นต้น
    \idxboth{การเรียนรู้แบบส่งต่อ}{Transfer Learning}

    \item[Unsupervised Learning] การเรียนรู้ของโมเดลแบบไม่มีผู้สอน (Output-free)
    ซึ่งยังสามารถแบ่งออกได้เป็นสองประเภทคือ 1. Binary Classification กับ 2. Multi-class Classification
    \idxboth{การเรียนรู้แบบมีไม่มีผู้สอน}{Unsupervised Learning}

    \item[Validation Set] ชุดข้อมูลสำหรับประเมินประสิทธิภาพของโมเดลก่อนที่จะนำไปทดสอบกับ Test Set จริง 
    โดย Dataset ประเภทนี้มักจะถูกนำมาใช้ในการทำ Cross-validation
    \idxboth{ชุดข้อมูล!ชุดข้อมูลสำหรับการประเมินผล}{Validation Set}
\end{description}

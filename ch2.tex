% LaTeX source for ``การเรียนรู้ของเครื่องสำหรับเคมีควอนตัม (Machine Learning for Quantum Chemistry)''
% Copyright (c) 2022 รังสิมันต์ เกษแก้ว (Rangsiman Ketkaew).

% License: Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)
% https://creativecommons.org/licenses/by-nc-nd/4.0/

\chapter{การเรียนรู้แบบมีผู้สอน}
\label{ch:sup_ml}

การเรียนรู้แบบมีผู้สอนหรือ Supervised learning เป็นเทคนิคแรก ๆ ที่ถูกพัฒนาขึ้นมาในช่วงยุคเริ่มต้นของ ML ซึ่งเป็นแนวคิดที่ใช้ Input และ 
Output ในการเทรนโมเดล ซึ่งผู้เขียนมีความคิดเห็นส่วนตัวว่าการสร้าง Model ประเภทนี้จะง่าย ๆ ที่สุดทั้งในแง่ทฤษฎี การเรียนรู้ และการนำไปใช้ 
โดยเทคนิคนี้ได้รับความนิยมมากที่สุดนั่นก็เพราะว่าสามารถนำไปประยุกต์ใช้งานกับโจทย์ที่หลากหลาย

%--------------------------
\section{Linear Regression}
%--------------------------

เทคนิคของการเรียนรู้แบบมีผู้สอนที่พื้นฐานที่สุดและได้รับความนิยมอย่างมากในช่วงยุคแรกของปัญญาประดิษฐ์ก็คือการถดถอยแบบเชิงเส้น (Linear Regression)
สมมติว่าเราพิจารณาชุดข้อมูลที่มีตัวแปรต้น 2 ตัว ($x_{1}$ และ $x_{2}$) และมีตัวแปรตาม 1 ตัว (y) ซึ่งตัวแปรตามในที่นี้ก็คือคำตอบหรือเป้าหมายที่%
เราต้องการทำนายนั่นเอง โดยยกตัวอย่างเช่น กำหนดให้ $x_{1}$ คเป็นจำนวนพันธะเดี่ยวในโมเลกุล $x_{2}$ เป็นจำนวนวงอะโรมาติก (Aromatic)
ในโมเลกุล และ $y$ เป็นค่าพลังงานรวมของโมเลกุล เราพบว่าเราสามารถสร้างหรือกำหนดสมการที่อธิบายความสัมพันธ์ระหว่างตัวแปรทั้งสามตัวนี้ได้%
แบบง่าย ๆ ดังนี้

\begin{equation}
    h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2
\end{equation}

\noindent โดยที่ $x$ ในที่นี้คือเวกเตอร์แบบสองมิติในปริภูมิ $\mathbb{R}^{2}$ และ $\theta_{i}$ คือพารามิเตอร์หรือเรียกว่าน้ำหนัก (Weights) ก็ได้ ซึ่งจะเป็นตัวแปรที่ปรับความเชื่อมโยง (Mapping) 
ระหว่าง $x_{i}$ และ $y$ ซึ่งเราสามารถเขียนให้อยู่ในรูปทั่วไปได้ดังนี้

\begin{align}
    h(x) &= \sum_{i=0}^{d} \theta_{i} x_{i} \\
         &= \theta^{\top} x
\end{align}

\noindent โดยสมการด้านบนนั้นจะเขียนในรูปของผลคูณระหว่างเวกเตอร์ของพารามิเตอร์ ($\theta^{\top}$) และเวกเตอร์ $x$

ลำดับถัดมาคือเราจะทำการปรับพารามิเตอร์ $\theta$ อย่างไรเพื่อให้ได้ชุดพารามิเตอร์ที่ทำการ Mapping ได้ดีที่สุด คำตอบก็คือเราสามารถทำได้โดย%
การกำหนดฟังก์ชันที่จะเป็นตัววัดพารามิเตอร์ $\theta_{i}$ ทีละตัว ซึ่งเรากำหนดและเรียกฟังก์ชันที่จะมาช่วยเราว่า Cost Function (Loss Function)
โดยมีรูปสมการทั่วไปดังต่อไปนี้ 

\begin{equation}
    J(\theta) = \frac 1 2 \sum_{i=1}^n \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2
\end{equation}

\noindent ซึ่งจะมีความคล้ายกันกับ Ordinary Least Square นั่นเอง โดยในหัวข้อต่อไปเราจะมาดูรายละเอียดของเทคนิคที่เราสามารถนำมาใช้%
ในการแก้ปัญหาของ Coss Function

%--------------------------
\section{Linear Classification}
%--------------------------

เราจะมาดู Linear Regression โดยการใช้เทคนิคที่ชื่อว่า Logistic Regression หลายคนอาจจะสงสัยว่า ชื่อของเทคนิคนี้มีคำว่า Regression 
แต่มันถึงเป็นเทคนิคที่เอามาใช้กับโจทย์แบบ Classification

%--------------------------
\section{เทคนิคอื่น ๆ}
%--------------------------

%--------------------------
\subsection{Partial Least Squares (PLS)}
%--------------------------

วิธีกำลังสองน้อยที่สุดบางส่วน (partial least squares: PLS) 
เป็นวิธีเชิงสถิติที่ใช้สำหรับการวิเคราะห์หลาย ตัวแปรเพื่อสร้างตัวแบบความสัมพันธ์ระหว่างกลุ่มของ ตัวแปรทำนาย (Predictor Variable) 
โดยอาศัยตัวแปรแฝง (Latent variable) ซึ่งเทคนิคนี้มีความคล้ายกับ Principle Component Analysis (PCA) 
ซึ่งจะเป็นการลดจำนวนมิติของข้อมูล.\cite{wold1984} ในช่วงยุคเริ่มต้นของ AI ในด้านเคมี เทคนิคนี้ได้ถูกนำมาใช้อย่างแพร่หลาย เช่น 
นำมาใช้สำหรับการระบุ Vibrational Bands สำหรับ Vibrational Spectra และนำผลที่ได้มาเปรียบเทียบกับค่าการทำนายที่ได้จากวิธีอื่น เช่น
ANN และ PCA-ANN.

%--------------------------
\subsection{Gaussian Process Regression (GPR)}
%--------------------------

การถดถอยของกระบวนการเกาส์เซียน เป็นวิธีการถดถอยของเบส์แบบหนึ่งโดยใช้ Kernel Function ที่สามารถบ่งบอกหรือแสดงค่าความแปรปรวน (covariance) 
ในขั้นตอน Gaussian Process ได้\cite{rasmussen2005} โดย GPR จะทำการสร้างโมเดลแบบ Non-parametric และสามารถคำนวณค่าความเชื่อมั่น 
(Confidence intervals) ไปพร้อม ๆ กับการทำนาย

%--------------------------
\subsection{Random Forest}
%--------------------------

Random Forest (RF) เป็นวิธีหนึ่งในกลุ่มของโมเดลที่เรียกว่า Ensemble Learning (การเรียนรู้แบบกลุ่มก้อน) 
ที่มีหลักการคือการเทรนโมเดลที่เหมือนกันหลาย ๆ ครั้ง (Multitude) บนข้อมูลชุดเดียวกัน โดยแต่ละครั้งของการเทรนจะเลือกส่วนของข้อมูลที่เทรนไม่เหมือนกัน 
แล้วเอาการตัดสินใจของโมเดลเหล่านั้นมาโหวตกันว่า Class ไหนถูกเลือกมากที่สุด\cite{breiman2001,quinlan1986}

%--------------------------
\subsection{Artificial Neural Network}
%--------------------------

Artificial Neural Network (ANN) โครงสร้างประสาทเทียมเป็นอัลกอริทึมรูปแบบหนึ่งที่เลียนแบบการทำงานของสมองมนุษย์
โดยทำการสร้างโมเดลเรียนรู้ที่ประกอบไปด้วยชั้นเรียนรู้ระหว่างกลาง (Hidden Layer) และหน่วยย่อยที่เกิดการเรียนรู้ (Node หรือ Artificial Neuron หรือ Unit)

โดยโมเดล ANN ที่มีการนำไปใช้มากที่สุดคือเครือข่ายประสาทแบบป้อนไปหน้า (Feedforward Network) และ ANN ยังสามารถแบ่งออกเป็น
หลายประเภท ดังนี้

\begin{itemize}
    \item เพอร์เซ็ปตรอนชั้นเดียว (Single-layer Perceptron)
    \item เพอร์เซ็ปตรอนหลายชั้น (Multi-layer Perceptron
    \item โครงข่ายแบบวนซ้ำ (Recurrent Network)
    \item แผนผังจัดระเบียบเองได้ (Self-organizing Map)
    \item เครื่องจักรโบลทซ์แมน (Boltzmann Machine)
    \item กลไกแบบคณะกรรมการ (Committee of Machines)
    \item โครงข่ายความสัมพันธ์ (Associative Neural Network)
    \item โครงข่ายกึ่งสำเร็จรูป (Instantaneously Trained Networks)
    \item โครงข่ายแบบยิงกระตุ้น (Spiking Neural Networks) 
\end{itemize}
